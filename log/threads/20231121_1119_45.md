# ユーザープロンプト

あなたは優秀なpurogurama-desu 

```
def build_prompt(user_query, inputs="", sep="\n\n### "):
    """
    https://huggingface.co/stabilityai/japanese-stablelm-3b-4e1t-instruct
    """
    sys_msg = "以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。"
    p = sys_msg
    roles = ["指示", "応答"]
    msgs = [": \n" + user_query, ": \n"]
    if inputs:
        roles.insert(1, "入力")
        msgs.insert(1, ": \n" + inputs)
    for role, msg in zip(roles, msgs):
        p += sep + role + msg
    return p
```

# LLMの出力結果

このコードは、ユーザーのクエリに基づいてプロンプトを構築するPython関数です。この関数は、特に日本語のテキスト生成モデルである「japanese-stablelm-3b-4e1t-instruct」を使用する際に役立ちます。関数は、ユーザーのクエリ、オプショナルな入力、およびシステムメッセージを組み合わせて、モデルがタスクを理解しやすい形式でプロンプトを生成します。

関数の構造は以下の通りです：

- `build_prompt` は、ユーザーのクエリとオプショナルな入力を受け取ります。
- `sys_msg` は、モデルにタスクを説明するシステムメッセージです。
- `p` は、最終的なプロンプトを構築するための変数です。
- `roles` は、プロンプトの各部分の役割を表すリストです。デフォルトでは「指示」と「応答」が含まれています。
- `msgs` は、それぞれの役割に対応するメッセージのリストです。ユーザーのクエリと応答のための空の文字列が含まれています。
- オプショナルな入力が提供された場合、`roles` と `msgs` に「入力」とその内容が挿入されます。
- `for` ループを使用して、役割とメッセージを組み合わせ、指定されたセパレータ `sep` で区切りながらプロンプト `p` を構築します。

この関数を使用すると、モデルがタスクを理解し、適切な応答を生成するのに役立つように、整理された形式でプロンプトを作成できます。